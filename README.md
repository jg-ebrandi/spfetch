# ğŸš€ spfetch

![spfetch_lg](https://github.com/user-attachments/assets/c66f083b-3899-4482-94da-1f85609b357e)



<p align="center">
  <b>Simple. Streaming. MFA-ready.</b><br>
  List and fetch files from <b>SharePoint</b> via <b>Microsoft Graph</b> with clean APIs and cloud-native downloads.
</p>

---

## âœ¨ What is spfetch?

`spfetch` is a Python library to:

- ğŸ“‚ List SharePoint folders  
- â¬‡ï¸ Download files in streaming mode  
- â˜ï¸ Send files directly to S3 / GCS / ADLS  
- ğŸ” Authenticate with MFA (Device Code Flow)  
- ğŸ“Š Optionally read small files into pandas  

Built for data engineers and analytics workflows that need reliability and simplicity.

---

## ğŸ¤” Why?

Accessing SharePoint programmatically usually involves:

- ğŸ” Complex authentication flows (MFA included)  
- ğŸ” Confusing browser URLs vs API paths  
- ğŸš¦ Throttling (HTTP 429)  
- ğŸ§  Memory issues when handling large files  

`spfetch` solves this with:

- âœ… MFA-compatible authentication  
- âœ… Streaming-first downloads (no full in-memory load)  
- âœ… fsspec integration (cloud-native destinations)  
- âœ… Minimal and explicit API  

---

## ğŸ“¦ Installation

### Core

```bash
pip install spfetch
```

---

### â˜ï¸ Cloud destinations (optional)

```bash
pip install spfetch[s3]     # Amazon S3 (s3fs)
pip install spfetch[gcs]    # Google Cloud Storage (gcsfs)
pip install spfetch[azure]  # Azure Data Lake (adlfs)
```

---

### ğŸ“Š Pandas helpers (optional)

```bash
pip install spfetch[pandas]
```

---

# ğŸš€ Quickstart

---

## ğŸ” 1ï¸âƒ£ Authenticate (Device Code / MFA)

```python
import spfetch as sp

client = sp.connect_device_code(
    tenant_id="YOUR_TENANT_ID",
    client_id="YOUR_CLIENT_ID",
)
```

âœ”ï¸ Works with MFA-enabled accounts  
âœ”ï¸ No secrets required  
âœ”ï¸ Ideal for local development  

---

## ğŸ“‚ 2ï¸âƒ£ List a Folder

```python
items = client.ls(
    site_url="https://tenant.sharepoint.com/sites/MySite",
    folder="/Shared Documents/Reports",
)

for item in items:
    print(item.name, item.is_folder, item.size)
```

Returns structured metadata for files and folders.

---

## â¬‡ï¸ 3ï¸âƒ£ Streaming Download (Recommended for Large Files)

### ğŸ–¥ï¸ Download to Local Filesystem

```python
client.download(
    site_url="https://tenant.sharepoint.com/sites/MySite",
    path="/Shared Documents/Big/base.csv",
    dst="stage/base.csv",
)
```

---

### â˜ï¸ Download Directly to Cloud Storage

```python
client.download(
    site_url="https://tenant.sharepoint.com/sites/MySite",
    path="/Shared Documents/Big/base.csv",
    dst="gs://my-bucket/stage/base.csv",  # or s3://... or abfss://...
)
```

ğŸ”¥ Files are streamed in chunks â€” no full in-memory loading.

Perfect for large CSVs, parquet files, exports, and data pipelines.

---

## ğŸ“Š 4ï¸âƒ£ Read Small Files into pandas (Optional)

```python
df = client.read_excel(
    site_url="https://tenant.sharepoint.com/sites/MySite",
    path="/Shared Documents/Reports/sales.xlsx",
    sheet_name="Base",
    usecols="B:F",
    skiprows=8,
)
```

> âš ï¸ For very large files, prefer `download()` and process them using Spark, Dask, or your data engine of choice.

---

# ğŸ” Microsoft Entra ID (Azure AD) Setup

To use `spfetch`, create an **App Registration** in Microsoft Entra ID.

---

## ğŸ§­ Setup Steps

1. Create an **App Registration**
2. Copy the `tenant_id`
3. Copy the `client_id`
4. Enable **Public client flows** (Device Code flow)
5. Grant required Microsoft Graph permissions
6. (If needed) Request **Admin Consent**

---

## ğŸ”‘ Required Permissions

Minimum permissions depend on your use case.

### ğŸ“– Read-only access

```
Sites.Read.All
```

### âœï¸ Read & Write access

```
Sites.ReadWrite.All
```

Some tenants may require:

- Admin consent  
- Site-specific permission configuration  

---

# ğŸ§± Design Principles

- ğŸ” MFA-first authentication  
- ğŸŒŠ Streaming over buffering  
- â˜ï¸ Cloud-native architecture  
- ğŸ§© Minimal API surface  
- ğŸ” Explicit behavior over magic  

---

# ğŸ—ºï¸ Roadmap

Planned features:

- ğŸ”‘ `connect_client_secret()` for pipelines / CI  
- ğŸ”„ `sync_folder()` with ETag / Last-Modified support  
- ğŸ§­ Path and URL normalization helpers  
- ğŸ“Š Richer metadata filtering  
- ğŸ” Configurable retry / backoff strategy  

---

# ğŸ¤ Contributing

PRs are welcome!

Please:

- Add tests for new features  
- Keep public APIs documented  
- Maintain backward compatibility when possible  

---

# ğŸ“„ License

MIT

---

<p align="center">
  Built for modern data workflows ğŸš€
</p>
